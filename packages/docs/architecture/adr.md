# ADR-001: PR Review Agent Architecture

**Status:** Implemented âœ… (Layer 0 â€” the foundation of the v2 monorepo)

---

## Context

AgnusAI is an AI-powered PR review agent that:
- Reviews pull requests on **GitHub** and **Azure DevOps**
- Posts **rich inline comments** on specific diff lines with severity, steps of reproduction, and AI fix prompts
- Uses **Vercel AI SDK** with a unified backend supporting Ollama, OpenAI, Azure OpenAI, and any OpenAI-compatible endpoint
- Runs via CLI or CI/CD pipeline â€” no continuously running service (in Layer 0)

### Constraints
- Must work locally with no external LLM API required (Ollama)
- Support multiple VCS platforms without duplicating review logic
- Prompt building and response parsing must be shared across all LLM providers
- Token budget: ~30K characters for diff content
- Azure DevOps has no unified diff endpoint â€” diffs must be computed from file content

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CI/CD Pipeline or CLI                         â”‚
â”‚          (GitHub Actions / Azure Pipelines / Terminal)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PRReviewAgent                             â”‚
â”‚                   packages/reviewer/src/index.ts                 â”‚
â”‚                                                                  â”‚
â”‚  1. Fetch PR metadata, diff, and files from VCS                 â”‚
â”‚  2. Match applicable skills by file glob patterns               â”‚
â”‚  3. Build ReviewContext â†’ call LLM.generateReview()             â”‚
â”‚  4. Validate comment paths against actual diff file list        â”‚
â”‚  5. Post comments via VCS adapter                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                       â”‚
          â–¼                    â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VCS Adapters   â”‚  â”‚    LLM Backends      â”‚  â”‚  Skill Loader    â”‚
â”‚  src/adapters/   â”‚  â”‚    src/llm/          â”‚  â”‚  src/skills/     â”‚
â”‚                  â”‚  â”‚                      â”‚  â”‚                  â”‚
â”‚  GitHubAdapter   â”‚  â”‚  BaseLLMBackend      â”‚  â”‚  Reads SKILL.md  â”‚
â”‚  AzureDevOps     â”‚  â”‚  (abstract)          â”‚  â”‚  files, matches  â”‚
â”‚  Adapter         â”‚  â”‚                      â”‚  â”‚  by glob pattern â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚  â”‚  prompt.ts     â”‚  â”‚
                      â”‚  â”‚  (shared)      â”‚  â”‚
                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                      â”‚  â”‚  parser.ts     â”‚  â”‚
                      â”‚  â”‚  (shared)      â”‚  â”‚
                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                      â”‚                      â”‚
                      â”‚  Unified Backend      â”‚
                      â”‚  (Vercel AI SDK)      â”‚
                      â”‚  - Ollama             â”‚
                      â”‚  - OpenAI             â”‚
                      â”‚  - Azure OpenAI       â”‚
                      â”‚  - Custom endpoint    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Design Decisions

### Decision 1: Unified Backend with Vercel AI SDK

**Problem:** Initially had three separate LLM backends (Ollama, Claude, OpenAI) duplicating `buildReviewPrompt`, `buildDiffSummary`, and `parseReviewResponse` â€” ~400 lines of duplicated code.

**Decision:** Use Vercel AI SDK's `@ai-sdk/openai-compatible`. Single `UnifiedLLMBackend` supports any OpenAI-compatible endpoint via `baseURL` + `apiKey`.

**Result:** Adding a new provider requires only a config entry. Works with Ollama, OpenAI, Azure OpenAI, LM Studio, vLLM, and any custom endpoint.

---

### Decision 2: Azure DevOps LCS Diff

**Problem:** The Azure DevOps `/iterations/{id}/changes` endpoint returns file change metadata but not actual diff content.

**Decision:** Fetch file content at `sourceRefCommit` and `commonRefCommit` (merge base) for each changed file, then compute a unified diff using an LCS algorithm.

**Trade-offs:**
- Extra API calls (2 per changed file)
- LCS is O(mÃ—n), capped at 600k line pairs; falls back to full-replacement diff for very large files
- Result: real `+`/`-` line diffs the LLM can meaningfully analyse

---

### Decision 3: LLM Generates Full Markdown Body

**Problem:** Early versions built comment templates from structured fields (severity, impacts, steps) extracted from the LLM response. Local models didn't reliably follow structured formats.

**Decision:** Show the LLM a concrete example of the full rendered markdown comment. The LLM writes the entire body. The parser only extracts `[File: path, Line: N]` for positioning.

**Result:** More natural output, fewer parsing failures, easier to customise by changing the prompt example.

---

### Decision 4: Path Normalisation

**Problem:** Azure DevOps stores file paths with a leading `/`. The LLM may omit it. Thread context `filePath` must match exactly, or Azure DevOps returns "file not found".

**Decision:** In `postReview`, build a `Map<normalisedPath, originalPath>`. Each comment's path is looked up after stripping the leading `/`. Comments with no matching path are skipped with a warning.

---

### Decision 5: Pipeline-Triggered Model (Layer 0)

**Decision:** The agent runs as a single-shot CLI process triggered by CI/CD â€” not a long-running server.

**Benefits:** No idle costs, no state management, no long-lived tokens, scales with CI runners.

**Evolution:** v2 adds a long-running Fastify server (Layer 2) for webhook-driven reviews with graph context. Layer 0 remains unchanged.

---

## Comment Format

Each inline comment uses this structure:

```markdown
**Suggestion:** [one-sentence description of the issue] [tag]

<details>
<summary><b>Severity Level:</b> Major âš ï¸</summary>

- âš ï¸ First concrete consequence
- âš ï¸ Second concrete consequence
</details>

```suggestion
corrected_code_here()
```

**Steps of Reproduction:**

<details>
<summary><b>Steps of Reproduction âœ…</b></summary>

1. Step one
2. Step two
</details>

<details>
<summary><b>Prompt for AI Agent ğŸ¤–</b></summary>

This is a comment left during a code review.
**Path:** /src/file.py
**Line:** 42
**Comment:** ...
Validate the correctness of the flagged issue. If correct, how can I resolve this?
</details>
```

---

## Technology Stack

| Component | Technology |
|-----------|------------|
| Language | TypeScript / Node.js â‰¥ 18 |
| CLI Framework | `commander` |
| GitHub API | `@octokit/rest` |
| Azure DevOps API | `node-fetch` (REST) |
| LLM â€” Local | Ollama via Vercel AI SDK |
| LLM â€” Cloud | OpenAI, Azure OpenAI, Claude via Vercel AI SDK |
| Diff Algorithm | Myers LCS (custom implementation) |
| Build Tool | `tsc` (TypeScript compiler) |

---

## Consequences

**Positive:**
- Consistent review quality across all PRs
- Provider-agnostic: swap LLM without touching prompts or parsing
- Works fully offline with Ollama
- Rich, actionable comment format with AI fix prompts

**Negative:**
- Local models may not follow the output format as reliably as cloud models
- Azure DevOps diff requires NÃ—2 API calls for N changed files
- Token limits cap diff size at ~30k characters

**Risks mitigated:**
- LLM hallucinating file paths â†’ path validation against actual diff
- LLM output format drift â†’ concrete example in prompt + fallback parser
- Azure rate limits â†’ sequential file fetching
